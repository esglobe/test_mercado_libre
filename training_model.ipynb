{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model\n",
    "\n",
    "By: Javier Mart√≠nez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "                             accuracy_score,precision_score,recall_score, roc_curve, auc)\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_MeLi_ = pd.read_pickle('./data/data_base.pkl')\n",
    "pd_MeLi = pd_MeLi_.set_index('id',drop=True).copy()\n",
    "\n",
    "pd_MeLi['initial_quantity'] = pd_MeLi['initial_quantity'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = ['title_new',\n",
    "                'local_pick_up',\n",
    "                'free_shipping',\n",
    "                'mode',\n",
    "                'variations_boolean',\n",
    "                'accepts_mercadopago_boolean',\n",
    "                'currency_id_boolean',\n",
    "                #'date_created_format',\n",
    "                'attributes_boolean',\n",
    "                'automatic_relist_boolean',\n",
    "                'video_id_boolean',\n",
    "                #'sub_status_new',\n",
    "                # 'deal_ids_new',\n",
    "                #'seller_address_country',\n",
    "                'seller_address_state',\n",
    "                #'seller_address_city',\n",
    "                'base_price',\n",
    "                #'seller_id',\n",
    "                'category_id',\n",
    "                'listing_type_id',\n",
    "                'buying_mode',\n",
    "                #'last_updated',\n",
    "                #'start_time',\n",
    "                #'parent_item_id',\n",
    "                'initial_quantity',\n",
    "                #**'price',\n",
    "                'status',\n",
    "                #'original_price',\n",
    "                #'official_store_id',\n",
    "                'sold_quantity',\n",
    "                #'catalog_product_id',\n",
    "                'available_quantity',\n",
    "                #'deal_ids',\n",
    "                'condition_new',\n",
    "                'training_data'\n",
    "                ]\n",
    "\n",
    "\n",
    "pd_model = pd_MeLi[all_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = [ 'mode',\n",
    "            #'category_id',\n",
    "            'listing_type_id',\n",
    "            'buying_mode',\n",
    "            'status',\n",
    "            'seller_address_state'\n",
    "            ]\n",
    "\n",
    "pd_x_data = pd.get_dummies(pd_model,columns=dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = ['initial_quantity',\n",
    "            #'price',\n",
    "            'base_price',\n",
    "            'available_quantity',\n",
    "            'sold_quantity'\n",
    "            ]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(pd_x_data[numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_x_data[numbers] = scaler.transform(pd_x_data[numbers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'condition_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "pandas_x_training = pd_x_data.query('training_data==1').copy()\n",
    "pandas_y_training = pandas_x_training[out]\n",
    "pandas_x_training.drop(labels=['training_data',out],axis=1,inplace=True)\n",
    "pandas_x_training.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "pandas_x_test = pd_x_data.query('training_data==0').copy()\n",
    "pandas_y_test = pandas_x_test[[out]]\n",
    "pandas_x_test.drop(labels=['training_data',out],axis=1,inplace=True)\n",
    "pandas_x_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class XGB_MODEL():\n",
    "    \"\"\"\n",
    "    model training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,pandas_x_training,\n",
    "                    pandas_y_training,\n",
    "                    pandas_x_test,\n",
    "                    pandas_y_test):\n",
    "\n",
    "        self.pandas_x_training = pandas_x_training\n",
    "        self.pandas_y_training = pandas_y_training\n",
    "        self.pandas_x_test = pandas_x_test\n",
    "        self.pandas_y_test = pandas_y_test\n",
    "\n",
    "    def training(self,n_estimators):\n",
    "\n",
    "        np.random.seed(0)\n",
    "        # Model\n",
    "        self.model = XGBClassifier(n_estimators=n_estimators,\n",
    "                                   verbosity=0)\n",
    "\n",
    "        # Fit\n",
    "        self.model.fit(self.pandas_x_training.values,\n",
    "                      self.pandas_y_training.values\n",
    "                    )\n",
    "\n",
    "        # Metrics\n",
    "        self.prediction = self.model.predict(pandas_x_test.values)\n",
    "        self.accuracy = accuracy_score(self.pandas_y_test.values, self.prediction)\n",
    "        self.precision = precision_score(pandas_y_test.values, self.prediction)\n",
    "        self.recall =recall_score(self.pandas_y_test.values, self.prediction)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(self.pandas_y_test.values, self.prediction, pos_label=1)\n",
    "        self.auc = auc(fpr, tpr)\n",
    "\n",
    "        self.confusion_matrix = confusion_matrix(self.pandas_y_test.values,self.prediction)\n",
    "\n",
    "        # Plot\n",
    "        self.plot_matrix = ConfusionMatrixDisplay(confusion_matrix=self.confusion_matrix)\n",
    "\n",
    "        # Summary\n",
    "        self.summary = pd.DataFrame({'accuracy':self.accuracy,\n",
    "                                    'precision':self.precision,\n",
    "                                    'recall':self.recall,\n",
    "                                    'auc':self.auc,\n",
    "                                    'n_estimators':n_estimators},index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================\n",
    "def select_model(n_estimators):\n",
    "    xgb_model = XGB_MODEL(pandas_x_training,\n",
    "                        pandas_y_training,\n",
    "                        pandas_x_test,\n",
    "                        pandas_y_test)\n",
    "    xgb_model.training(n_estimators=n_estimators)\n",
    "    return xgb_model\n",
    "#==================\n",
    "\n",
    "\n",
    "# Training models\n",
    "models = list(map(lambda x: select_model(x),[50,100,150,200,250,300,350]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary models\n",
    "summary_models = pd.concat(list(map(lambda x: x.summary, models)))\n",
    "summary_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "best_model = list(filter(lambda x: x.accuracy == summary_models.accuracy.max(),models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Best Model\n",
    "best_model[0].confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Plot Best Model\n",
    "best_model[0].plot_matrix.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('analisis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd1b4e18fb74f565c8fc9642e64dc5ff934c7c3ac8741d3f6831ae7dbdee96fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
